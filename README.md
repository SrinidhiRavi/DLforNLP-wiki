# Deep Learning for NLP - wiki
Wiki for the Deep Learning for Natural Language Processing [course](http://www.csa.iisc.ernet.in/academics/academics-courses-desc.php#E0334) at Indian Institute of Science, Bangalore - Aug 2017 to Dec 2017

## -----------------------------------------------------------------------------

## Project Groups
	1. Understanding the Geometrical Relationship among Word Vectors - Aditya Sharma, Chandrahas
	2. Comparative Study of Neural Language Models - Abhinash Khare, Soham Pal, Sruthi Gorantla
	3. Document time stamping using Graph Convolutional Networks - Shikhar, Swayambhu, Shib Shankar
	4. Hierarchical attention network - Vaijenath, Anil, Pratik
	5. Question Answer System - Rohith AP, Ronit Halder, V Nidhin Krishnan.
	6. Combined Neural Models: Comparison and Analysis - Soumalya, Srinighi, Bala
	7. Transfer Learning for NLP with application to detecting duplicate question pairs - Krishna, Rantej, Ravi
	8. Neural Machine Translation - Kinsuk Sarkar, Maulik Parmar, Ayappa Kumar
	9. Topic Modeling - Tushar, Sridhar
	10. Reinforcement Learning for NLP - Keshav
	11. Classification using Sentence Level Embedding - Shikhar Verma, Nitin Kumar, Shubham Goel

	
  
## -----------------------------------------------------------------------------

## Papers Covered by Students

### Understanding the Geometrical Relationship among Word Vectors
Team Members - Aditya Sharma, Chandrahas
1. October 13th, 2017:
	* Levy, O. and Goldberg, Y., 2014. **Neural word embedding as implicit matrix factorization**. In Advances in neural information processing systems (pp. 2177-2185). [[Paper]](http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf)
	* Levy, O., Goldberg, Y. and Dagan, I., 2015. **Improving distributional similarity with lessons learned from word embeddings**. Transactions of the Association for Computational Linguistics, 3, pp.211-225. [[Paper]](http://www.aclweb.org/anthology/Q15-1016)
	* Mimno, D. and Thompson, L., 2017. **The strange geometry of skip-gram with negative sampling.** In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (pp. 2863-2868). [[Paper]](http://www.aclweb.org/anthology/D17-1307)

### Comparative Study of Neural Language Models
Team Members - Abhinash Khare, Soham Pal, Sruthi Gorantla
1. October 20th, 2017:
	* Wang Ling, Isabel Trancoso, Chris Dyer, Alan W Black. **Character-based Neural Machine Translation.** [[Paper]](https://arxiv.org/abs/1511.04586)
	* Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, Yonghui Wu. **Exploring the Limits of Language Modeling.** [[Paper]](https://arxiv.org/abs/1602.02410)
	* Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel Jurafsky, Christopher Manning. **A Conditional Random Field Word Segmenter.** [[Paper]](https://nlp.stanford.edu/pubs/sighan2005.pdf)

### Document time stamping using Graph Convolutional Networks
Team Members - Shikhar, Shib, Swayambhu
1. October 20th, 2017:
	* Defferrard, Michaël, Xavier Bresson, and Pierre Vandergheynst. **Convolutional neural networks on graphs with fast localized spectral filtering.** Advances in Neural Information Processing Systems. 2016. [[Paper]](http://papers.nips.cc/paper/6081-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering.pdf)
	* Marcheggiani, Diego, and Ivan Titov. **Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling.** arXiv preprint arXiv:1703.04826 (2017). [[Paper]](http://www.aclweb.org/anthology/D17-1159)

### Hierarchical attention network
Team Members - Vaijenath, Anil, Pratik
1. November 10th, 2017:
	* Yang, Z., Yang, D., Dyer, C., He, X., Smola, A.J. and Hovy, E.H., 2016. **Hierarchical Attention Networks for Document Classification**. In HLT-NAACL (pp. 1480-1489). [[Paper]](https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf)
	* Xu, J., Chen, D., Qiu, X. and Huang, X., **Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification**. [[Paper]](http://www.anthology.aclweb.org/D/D16/D16-1172.pdf)

### Question Answer System
Team Members - Rohith AP, Ronit Halder, V Nidhin Krishnan
1. November 10th, 2017:
	* Shuohang Wang, Jing Jiang **Machine Comprehension Using Match-LSTM and Answer Pointer.** [[Paper]](https://arxiv.org/abs/1608.07905)
	* Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes. **Reading Wikipedia to Answer Open-Domain Questions**. [[Paper]](https://arxiv.org/abs/1704.00051)
	* Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi,and Hannaneh Hajishirzi.  2016. **Bidirectional attention flow for machine comprehension.**[[Paper]](https://arxiv.org/pdf/1611.01603.pdf)

### Combined Neural Models: Comparison and Analysis
Team Members - Soumalya Seal, Srinidhi R, Balasubramaniam S
1. November 8th, 2017:
	* Xingyou Wang,Weijie Jiang, Zhiyong Luo, **Combination of Convolutional and Recurrent Neural Network for Sentiment Analysis of Short Texts.** [[Paper](https://pdfs.semanticscholar.org/a0c3/b9083917b6c2368ebf09483a594821c5018a.pdf)]
	* Chunting Zhou, Chonglin Sun, Zhiyuan Liu, Francis C.M. Lau, **A C-LSTM Neural Network for Text Classification**. [[Paper](https://arxiv.org/abs/1511.08630)]
	* Siwei Lai, Liheng Xu, Kang Liu, Jun Zhao, **Recurrent convolutional neural networks for text classification**. [[Paper](https://pdfs.semanticscholar.org/eba3/6ac75bf22edf9a1bfd33244d459c75b98305.pdf)]
	
	
### Transfer Learning for NLP with application to detecting duplicate question pairs -
Team Members -  Krishna Bharat, Rantej, Ravi Shankar
1. October 13th, 2017:
	* Lili Mou, Zhao Meng,Rui Yan, Ge Li, Yan Xu, Lu Zhang, Zhi Jin, **How Transferable are Neural Networks in NLP Applications?** [[Paper](https://arxiv.org/pdf/1603.06111.pdf)]
	* Zhilin Yang, Ruslan Salakhutdinov, William W Cohen, **Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks**. [[Paper](https://arxiv.org/pdf/1703.06345.pdf)]
	* Seunghyun Yoon, Hyeongu Yun, Yuna Kim, Gyu-tae Park, Kyomin Jung, **Efficient Transfer Learning Schemes for Personalized Language Modeling using Recurrent Neural Network**. [[Paper](https://arxiv.org/pdf/1701.03578.pdf)]
	
### Neural Machine Translation
Team Members - Kinsuk Sarkar, Maulik Parmar, Ayappa Kumar
1. October 20th, 2017:
	* Sutskever, I., Vinyals, O. and Le, Q.V, **Sequence to Sequence Learning with Neural Networks.** [[Paper](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)]
	* Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey, W., Krikun, M., Cao, Y., Gao, Q., Macherey, K. and Klingner, J., **Googles's Neural Machine Translation System:  Bridging the gap between Human and Machine Translation**. [[Paper](https://arxiv.org/pdf/1609.08144.pdf)]
	
	
### Topic Modeling
Team Members - Tushar, Sridhar
1. October 20th, 2017:
	* Moody, **Mixing Dirichlet Topic Models and Word Embeddings to Make lda2vec.** [[Paper](https://arxiv.org/abs/1605.02019)]
	* Sridhar, V.K.R., **Unsupervised Topic Modeling for Short Texts Using Distributed Representations of Words**. [[Paper](http://www.aclweb.org/anthology/W15-1526)]
	
### Reinforcement Learning for NLP
Team Members - Keshav
1. November 8th, 2017:
	* Yogatama, D., Blunsom, P., Dyer, C., Grefenstette, E. and Ling, W., **Learning to compose words into sentences with reinforcement learning.** [[Paper](https://arxiv.org/pdf/1611.09100.pdf)]
	* Tai, K.S., Socher, R. and Manning, C.D., **Improved semantic representations from tree-structured long short-term memory networks**. [[Paper](https://arxiv.org/pdf/1503.00075)]
	
	
### Classification using Sentence Level Embedding
Team Members - Shikhar Verma, Nitin Kumar, Shubham Goel
1. November 8th, 2017:
	* Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Urtasun, Sanja Fidler. 2015. **Skip Thought Vectors.** [[Paper](https://papers.nips.cc/paper/5950-skip-thought-vectors.pdf)]
	* Matteo Pagliardini, Prakhar Gupta, Martin Jaggi. 2017. **Unsupervised Learning of Sentence Embeddings using Compositional n-gram features**. [[Paper](https://arxiv.org/pdf/1703.02507.pdf)]
	

## -----------------------------------------------------------------------------

## Papers Covered by Professors

### Basics of Optimization
* [Blog Post] Sebastian Ruder. **An overview of gradient descent optimization algorithms** [[Link](http://ruder.io/optimizing-gradient-descent/)]

### Word Vectors
* Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S. and Dean, J., 2013. **Distributed representations of words and phrases and their compositionality**. In Advances in neural information processing systems [[Paper](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality)]
* Pennington, J., Socher, R. and Manning, C., 2014. **Glove: Global vectors for word representation**. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) [[Paper](http://www.aclweb.org/anthology/D14-1162)]
* Wieting, J., Bansal, M., Gimpel, K. and Livescu, K., 2016. **Charagram: Embedding words and sentences via character n-grams**. [[Paper](https://arxiv.org/abs/1607.02789)]

### Language Modelling
* Bengio, Y., Ducharme, R., Vincent, P. and Jauvin, C., 2003. **A neural probabilistic language model**. Journal of machine learning research [[Paper](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)]
* Mikolov, T., Karafiát, M., Burget, L., Cernocký, J. and Khudanpur, S., 2010, September. **Recurrent neural network based language model**. In Interspeech (Vol. 2, p. 3). [[Paper](http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf)]
* Dauphin, Y.N., Fan, A., Auli, M. and Grangier, D., 2016. **Language modeling with gated convolutional networks**. [[Paper](https://arxiv.org/abs/1612.08083)]
* Zhao, H., Lu, Z. and Poupart, P., 2015, July. **Self-Adaptive Hierarchical Sentence Model**. In IJCAI [[Paper](http://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/download/10828/11307)]
* Conneau, A., Kiela, D., Schwenk, H., Barrault, L. and Bordes, A., 2017. **Supervised Learning of Universal Sentence Representations from Natural Language Inference Data**. In EMNLP [[Paper](http://aclweb.org/anthology/D/D17/D17-1070.pdf)]
* Kim, Y., Jernite, Y., Sontag, D. and Rush, A.M., 2016, February. **Character-Aware Neural Language Models**. In AAAI [[Paper](http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/viewFile/12489/12017)]


### Text Classification
* Joulin, A., Grave, E. and Mikolov, P.B.T., 2017. **Bag of Tricks for Efficient Text Classification**. EACL [[Paper](http://www.aclweb.org/anthology/E/E17/E17-2068.pdf)]
* Kim, Y., 2014. **Convolutional Neural Networks for Sentence Classification**. EMNLP [[Paper](https://arxiv.org/abs/1408.5882)]

### Networks
* Hochreiter, S. and Schmidhuber, J., 1997. **Long short-term memory**. Neural computation. [[Paper](http://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735)]
* [Blog Post] Christopher Olah. **Understanding LSTM Networks** [[Link](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)]
* Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I. and Salakhutdinov, R., 2014. **Dropout: a simple way to prevent neural networks from overfitting**. Journal of machine learning research [[Paper](http://jmlr.org/papers/v15/srivastava14a.html)]
* Chung, J., Gulcehre, C., Cho, K. and Bengio, Y., 2014. **Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling**. [[Paper](https://arxiv.org/abs/1412.3555)]
* Koch, G., Zemel, R. and Salakhutdinov, R., 2015. **Siamese neural networks for one-shot image recognition**. In ICML Deep Learning Workshop. [[Paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)]

### Neural Machine Translation
* Bahdanau, D., Cho, K. and Bengio, Y., 2014.**Neural machine translation by jointly learning to align and translate**. [[Paper](https://arxiv.org/abs/1409.0473)]
* Freitag, M. and Al-Onaizan, Y., 2017. **Beam Search Strategies for Neural Machine Translation**. [[Paper](https://arxiv.org/abs/1702.01806)] 

### Attention
* Yin, W., Schütze, H., Xiang, B. and Zhou, B., 2016. Abcnn: Attention-based convolutional neural network for modeling sentence pairs. In TACL [[Paper](http://www.anthology.aclweb.org/Q/Q16/Q16-1019.pdf)]

### Visualization
* Zeiler, M.D. and Fergus, R., 2014, September. **Visualizing and understanding convolutional networks**. In European conference on computer vision (pp. 818-833). Springer, Cham. [[Paper](https://arxiv.org/pdf/1311.2901.pdf)]
